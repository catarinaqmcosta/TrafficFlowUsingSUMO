import os, sys
#Files needed:
#'Output/messina_comune.net_speed35.xml'
#'Output/expo_affected_edge.csv'
#'Results_SUMO' folder must exist

# required arguments: loss_file loss_file_slight_dam start_rlz end_rlz rnd_seed
if len(sys.argv) < 5:
  sys.exit("exiting: some of the required arguments are missing")
  
loss_file = sys.argv[1]
loss_file_slight_dam = sys.argv[2]
start_rlz = sys.argv[3]
end_rlz = sys.argv[4]
rnd_seed = sys.argv[5]

import os.path
import csv
import sumolib
import pandas as pd
import random
from lxml import etree
import subprocess
import numpy as np

# load complete damage buildings csv and count number of realizations
full_df = pd.read_csv(loss_file, sep=',')
df = full_df.iloc[:, pd.np.r_[0:3, int(start_rlz)+3:int(end_rlz)+3+1]]
nr_realiz = len(df.columns) - 3
print("About to run "+str(nr_realiz)+" realizations.")
print("random seed: "+rnd_seed)
np.random.seed(int(rnd_seed))

# load slight damage buildings csv
full_df_slight = pd.read_csv(loss_file_slight_dam, sep=',')
df_slight = full_df_slight.iloc[:, pd.np.r_[0:3, int(start_rlz)+3:int(end_rlz)+3+1]]

# load edge that each building can block based on road blockage model (generated by expo_calculate_closest_edge_v2.py)
bldg_block_edge = pd.read_csv('Output/expo_affected_edge.csv', sep=',')

# parse the road network
roadnet = sumolib.net.readNet('Output/messina_comune.net_speed35.xml')

# create csv file where outputs will be saved, if it doesn't exist yet
if os.path.isfile('Output/results_sumo_realizations_'+start_rlz+'-'+end_rlz+'_'+rnd_seed+'.csv') is False:
  with open('Output/results_sumo_realizations_'+start_rlz+'-'+end_rlz+'_'+rnd_seed+'.csv', 'w', newline='') as sumo_output_file:
      wr = csv.writer(sumo_output_file)
      wr.writerow(["curr_realiz", "nr_complete_dmg", "nr_collapses", "nr_collapses_debris", "nr_closed_roads", "nr_slight_dam", "nr_vss", "nr_inserted", "nr_teleports", "avg_length", "avg_duration", "avg_timeloss", "ti_nr_trips", "ti_dur_mean", "ti_dur_median", "ti_length_mean", "ti_length_median"])

for i in range(nr_realiz):
  curr_realiz = df.columns[i+3]
  print(curr_realiz)
  
  curr_col = df.iloc[:, i+3]
  curr_complete_dmg = curr_col.index[curr_col == 1].values
  print("nr. buildings with complete damage: "+str(len(curr_complete_dmg)))
  curr_collapses = np.random.choice(curr_complete_dmg, round(len(curr_complete_dmg)*.2), replace=False)  # 20% of buildings with complete damage are considered to collapse, and are randomly selected here
  print("nr. collapses considered: "+str(len(curr_collapses)))
  # dataframe containing collapsed building ids for this realization
  curr_collapse_ids = df.iloc[curr_collapses, 2].values
  print(curr_collapse_ids)
  
  curr_col_slight = df_slight.iloc[:, i+3]
  curr_slight_dmg = curr_col_slight.index[curr_col_slight == 1].values
  print("nr. buildings with slight damage: "+str(len(curr_slight_dmg)))
  # dataframe containing buildings with slight damage for this realization
  curr_slight_dmg_df = df.iloc[curr_slight_dmg, 0:3]
  
  # define xml root
  root = etree.Element('additionals')
  root_slight_dam = etree.Element('additionals')

  nr_collapses_debris = 0
  nr_vss = 0

  # initialize empty list for already closed edges (avoid duplicate rerouter)
  already_closed = []
  already_closed_slight_dam = []

  # iterate over collapsed buildings
  for j in curr_collapse_ids:
    closed_road_id = bldg_block_edge[bldg_block_edge['bldg_id'] == j]['edge_id']  # edge that this building affects
    
    if (len(closed_road_id) > 0):
      nr_collapses_debris += 1
      closed_road_id_str = closed_road_id.values[0]
      
      if (closed_road_id_str not in already_closed):
        already_closed.append(closed_road_id_str)
        
        # write xml with rerouter info
        child1 = etree.Element('rerouter', id="rerouter_"+str(j), edges="322835431", probability="1.00")  # rerouter id is set this way such that it retains info on building that caused it
        root.append(child1)
        child2 = etree.Element('interval', begin="0", end="50000")
        child1.append(child2)

        child3 = etree.Element('closingLaneReroute', id=closed_road_id_str+"_0")
        child2.append(child3)
  
  # iterate over buildings with slight damage
  for row in curr_slight_dmg_df.itertuples(index = False):
    c_lon, c_lat = row[0], row[1]
    c_x, c_y = roadnet.convertLonLat2XY(c_lon, c_lat)
    
    # get closest edge to building with slight damage, so that its speed can be reduced
    neighbor_edges = roadnet.getNeighboringEdges(c_x, c_y, 100)
    
    if (len(neighbor_edges) > 0 and row[2] not in curr_collapse_ids):
      # sort by length
      sorted_neighbor_edges = sorted(neighbor_edges, key=lambda tup: tup[1])
      vss_road_id = sorted_neighbor_edges[0][0].getID()
      
      if (vss_road_id not in already_closed_slight_dam and vss_road_id not in already_closed):
        nr_vss += 1
        already_closed_slight_dam.append(vss_road_id)
        
        # write xml with variable speed info
        child11 = etree.Element('variableSpeedSign', id="vss_"+str(row[2]), lanes=vss_road_id+"_0")
        root_slight_dam.append(child11)
        child12 = etree.Element('step', time="0", speed="5.56")
        child11.append(child12)
      
  # pretty string
  s = etree.tostring(root, pretty_print=True)
  with open('./rerouter_'+start_rlz+'-'+end_rlz+'.xml', 'wb') as f:
    f.write(s)
    
  # pretty string
  s_slight = etree.tostring(root_slight_dam, pretty_print=True)
  with open('./variable_speed_'+start_rlz+'-'+end_rlz+'.xml', 'wb') as f:
    f.write(s_slight)
    
  # run SUMO
  subprocess.call(['sumo', '-c', 'run.sumo_messina_serverrun.sumocfg', '-a', 'rerouter_'+start_rlz+'-'+end_rlz+'.xml,variable_speed_'+start_rlz+'-'+end_rlz+'.xml,Output/taz_messina_v2-buffer.xml,Output/trips_messina_noshorttrips_taz_37k.xml', '--tripinfo-output', 'Results_SUMO/tripinfo_'+start_rlz+'-'+end_rlz+'.xml', '-l', 'Results_SUMO/sumo_log_'+start_rlz+'-'+end_rlz+'.txt'])

  # extract results
  with open('Results_SUMO/sumo_log_'+start_rlz+'-'+end_rlz+'.txt', 'r') as f:
    logstr = f.read()

  ins_start = logstr.find("Inserted: ") + 9
  if logstr.find("(Loaded: ") != -1:
    ins_end = logstr.find(" (", ins_start)
  else:
    ins_end = logstr.find("\n", ins_start)
  sumo_ins = int(logstr[ins_start:ins_end])

  tel_start = logstr.find("Teleports: ") + 11
  if tel_start > 10:  # run only if logstr.find did not return -1, meaning there were teleports
    tel_end = logstr.find(" (", tel_start)
    sumo_tel = int(logstr[tel_start:tel_end])
  else:
    sumo_tel = 0

  length_start = logstr.find("RouteLength: ", ins_end) + 13
  length_end = logstr.find("\n", length_start)
  sumo_length = float(logstr[length_start:length_end])

  dur_start = logstr.find("Duration: ", length_end) + 10
  dur_end = logstr.find("\n", dur_start)
  sumo_dur = float(logstr[dur_start:dur_end])

  tloss_start = logstr.find("TimeLoss: ", dur_end) + 10
  tloss_end = logstr.find("\n", tloss_start)
  sumo_tloss = float(logstr[tloss_start:tloss_end])
  
  # get results from tripinfo xml
  tree = etree.parse('Results_SUMO/tripinfo_'+start_rlz+'-'+end_rlz+'.xml')
  trip_durations = []
  trip_lengths = []
  for element in tree.iter('tripinfo'):
    trip_lengths.append(float(element.get('routeLength')))
    trip_durations.append(float(element.get('duration')))
  ti_nr_trips = len(trip_durations)
  ti_dur_mean = np.round(np.mean(trip_durations), 2)
  ti_dur_median = np.round(np.median(trip_durations), 2)
  ti_length_mean = np.round(np.mean(trip_lengths), 2)
  ti_length_median = np.round(np.median(trip_lengths), 2)
  
  with open('Output/results_closed_edges_'+start_rlz+'-'+end_rlz+'_'+rnd_seed+'.csv', 'a') as closed_edges_file:
    closed_edges_file.write("\n".join(already_closed)+"\n")
  
  # append output to csv
  with open('Output/results_sumo_realizations_'+start_rlz+'-'+end_rlz+'_'+rnd_seed+'.csv', 'a', newline='') as sumo_output_file:
    wr = csv.writer(sumo_output_file)
    wr.writerow([curr_realiz, len(curr_complete_dmg), len(curr_collapses), nr_collapses_debris, len(already_closed), len(curr_slight_dmg), nr_vss, sumo_ins, sumo_tel, sumo_length, sumo_dur,  sumo_tloss, ti_nr_trips, ti_dur_mean, ti_dur_median, ti_length_mean, ti_length_median])